{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a8adac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilad/Desktop/Projects/Semantic Decoding/semantic-decoding/decoding\n"
     ]
    }
   ],
   "source": [
    "%cd ../decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67082072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, dirname\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.stats as ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b99d9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from GPT import GPT\n",
    "from utils_stim import get_stim\n",
    "from utils_resp import get_resp\n",
    "from utils_ridge.ridge import ridge, bootstrap_ridge\n",
    "from utils_ridge.textgrid import TextGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcbf8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "639f6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIR = os.getcwd()\n",
    "DATA_LM_DIR = os.path.join(REPO_DIR, \"data_lm\")\n",
    "DATA_TRAIN_DIR = os.path.join(REPO_DIR, \"data_train\")\n",
    "DATA_TEST_DIR = os.path.join(REPO_DIR, \"data_test\")\n",
    "MODEL_DIR = os.path.join(REPO_DIR, \"models\")\n",
    "RESULT_DIR = os.path.join(REPO_DIR, \"results\")\n",
    "SCORE_DIR = os.path.join(REPO_DIR, \"scores\")\n",
    "\n",
    "# GPT encoding model parameters\n",
    "\n",
    "TRIM = 5\n",
    "STIM_DELAYS = [1, 2, 3, 4]\n",
    "RESP_DELAYS = [-4, -3, -2, -1]\n",
    "ALPHAS = np.logspace(1, 3, 10)\n",
    "NBOOTS = 50\n",
    "VOXELS = 10000\n",
    "CHUNKLEN = 40\n",
    "GPT_LAYER = 9\n",
    "GPT_WORDS = 5\n",
    "\n",
    "# decoder parameters\n",
    "\n",
    "RANKED = True\n",
    "WIDTH = 200\n",
    "NM_ALPHA = 2/3\n",
    "LM_TIME = 8\n",
    "LM_MASS = 0.9\n",
    "LM_RATIO = 0.1\n",
    "EXTENSIONS = 5\n",
    "\n",
    "# evaluation parameters\n",
    "\n",
    "WINDOW = 20\n",
    "\n",
    "# devices\n",
    "\n",
    "GPT_DEVICE = \"cpu\"\n",
    "EM_DEVICE = \"cpu\"\n",
    "SM_DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4562975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config\n",
    "from GPT import GPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd25a4",
   "metadata": {},
   "source": [
    "## Encoder Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41a53a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"UTS01\"\n",
    "gpt = \"perceived\"\n",
    "sessions = \"9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "929af84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIR = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d01a5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LM_DIR = os.path.join(REPO_DIR, \"data_lm\")\n",
    "DATA_TRAIN_DIR = os.path.join(REPO_DIR, \"data_train\")\n",
    "DATA_TEST_DIR = os.path.join(REPO_DIR, \"data_test\")\n",
    "MODEL_DIR = os.path.join(REPO_DIR, \"models\")\n",
    "RESULT_DIR = os.path.join(REPO_DIR, \"results\")\n",
    "SCORE_DIR = os.path.join(REPO_DIR, \"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51205d73",
   "metadata": {},
   "source": [
    "## Loading Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3efdf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMFeatures():\n",
    "    \"\"\"class for extracting contextualized features of stimulus words\n",
    "    \"\"\"\n",
    "    def __init__(self, model, layer, context_words):\n",
    "        self.model, self.layer, self.context_words = model, layer, context_words\n",
    "\n",
    "    def extend(self, extensions, verbose = False):\n",
    "        \"\"\"outputs array of vectors corresponding to the last words of each extension\n",
    "        \"\"\"\n",
    "        contexts = [extension[-(self.context_words+1):] for extension in extensions]\n",
    "        if verbose: print(contexts)\n",
    "        context_array = self.model.get_context_array(contexts)\n",
    "        embs = self.model.get_hidden(context_array, layer = self.layer)\n",
    "        return embs[:, len(contexts[0]) - 1]\n",
    "\n",
    "    def make_stim(self, words):\n",
    "        \"\"\"outputs matrix of features corresponding to the stimulus words\n",
    "        \"\"\"\n",
    "        context_array = self.model.get_story_array(words, self.context_words)\n",
    "        embs = self.model.get_hidden(context_array, layer = self.layer)\n",
    "        return np.vstack([embs[0, :self.context_words], \n",
    "            embs[:context_array.shape[0] - self.context_words, self.context_words]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "961ffad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = []\n",
    "with open(os.path.join(DATA_TRAIN_DIR, \"sess_to_story.json\"), \"r\") as f:\n",
    "    sess_to_story = json.load(f) \n",
    "for sess in sessions:\n",
    "    stories.extend(sess_to_story[str(sess)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc642c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_LM_DIR, gpt, \"vocab.json\"), \"r\") as f:\n",
    "    gpt_vocab = json.load(f)\n",
    "gpt = GPT(path = os.path.join(DATA_LM_DIR, gpt, \"model\"), vocab = gpt_vocab, device = config.GPT_DEVICE)\n",
    "features = LMFeatures(model = gpt, layer = config.GPT_LAYER, context_words = config.GPT_WORDS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a61689",
   "metadata": {},
   "source": [
    "## Train Encoding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebf0e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stim(stories, features, tr_stats = None):\n",
    "    \"\"\"extract quantitative features of stimulus stories\n",
    "    \"\"\"\n",
    "    word_seqs = get_story_wordseqs(stories)\n",
    "    word_vecs = {story : features.make_stim(word_seqs[story].data) for story in stories}\n",
    "    word_mat = np.vstack([word_vecs[story] for story in stories])\n",
    "    word_mean, word_std = word_mat.mean(0), word_mat.std(0)\n",
    "    \n",
    "    ds_vecs = {story : lanczosinterp2D(word_vecs[story], word_seqs[story].data_times, word_seqs[story].tr_times) \n",
    "               for story in stories}\n",
    "    ds_mat = np.vstack([ds_vecs[story][5+TRIM:-TRIM] for story in stories])\n",
    "    if tr_stats is None: \n",
    "        r_mean, r_std = ds_mat.mean(0), ds_mat.std(0)\n",
    "        r_std[r_std == 0] = 1\n",
    "    else: \n",
    "        r_mean, r_std = tr_stats\n",
    "    ds_mat = np.nan_to_num(np.dot((ds_mat - r_mean), np.linalg.inv(np.diag(r_std))))\n",
    "    del_mat = make_delayed(ds_mat, STIM_DELAYS)\n",
    "    if tr_stats is None: return del_mat, (r_mean, r_std), (word_mean, word_std)\n",
    "    else: return del_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cafac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp(subject, stories, stack = True, vox = None):\n",
    "    \"\"\"loads response data\n",
    "    \"\"\"\n",
    "    subject_dir = os.path.join(config.DATA_TRAIN_DIR, \"train_response\", subject)\n",
    "    resp = {}\n",
    "    for story in stories:\n",
    "        resp_path = os.path.join(subject_dir, \"%s.hf5\" % story)\n",
    "        hf = h5py.File(resp_path, \"r\")\n",
    "        resp[story] = np.nan_to_num(hf[\"data\"][:])\n",
    "        if vox is not None:\n",
    "            resp[story] = resp[story][:, vox]\n",
    "        hf.close()\n",
    "    if stack: return np.vstack([resp[story] for story in stories]) \n",
    "    else: return resp    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "181c0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_word_times(word_rate, resp, starttime = 0, tr = 2):\n",
    "    \"\"\"predict evenly spaced word times from word rate\n",
    "    \"\"\"\n",
    "    half = tr / 2\n",
    "    trf = TRFile(None, tr)\n",
    "    trf.soundstarttime = starttime\n",
    "    trf.simulate(resp.shape[0])\n",
    "    tr_times = trf.get_reltriggertimes() + half\n",
    "\n",
    "    word_times = []\n",
    "    for mid, num in zip(tr_times, word_rate):  \n",
    "        if num < 1: continue\n",
    "        word_times.extend(np.linspace(mid - half, mid + half, num, endpoint = False) + half / num)\n",
    "    return np.array(word_times), tr_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd11f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_wordseqs(stories):\n",
    "    \"\"\"loads words and word times of stimulus stories\n",
    "    \"\"\"\n",
    "    grids = load_textgrids(stories, DATA_TRAIN_DIR)\n",
    "    with open(os.path.join(DATA_TRAIN_DIR, \"respdict.json\"), \"r\") as f:\n",
    "        respdict = json.load(f)\n",
    "    trfiles = load_simulated_trfiles(respdict)\n",
    "    wordseqs = make_word_ds(grids, trfiles)\n",
    "    return wordseqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdac0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word_rate(resp, wt, vox, mean_rate):\n",
    "    \"\"\"predict word rate at each acquisition time\n",
    "    \"\"\"\n",
    "    delresp = make_delayed(resp[:, vox], RESP_DELAYS)\n",
    "    rate = ((delresp.dot(wt) + mean_rate)).reshape(-1).clip(min = 0)\n",
    "    return np.round(rate).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68c5d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_textgrids(stories, data_dir: str):\n",
    "    base = join(data_dir, \"train_stimulus\")\n",
    "    grids = {}\n",
    "    for story in stories:\n",
    "        grid_path = os.path.join(base, \"%s.TextGrid\" % story)\n",
    "        grids[story] = TextGrid(open(grid_path).read())\n",
    "    return grids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7beadc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulated_trfiles(respdict, tr=2.0, start_time=10.0, pad=5):\n",
    "    trdict = dict()\n",
    "    for story, resps in respdict.items():\n",
    "        trf = TRFile(None, tr)\n",
    "        trf.soundstarttime = start_time\n",
    "        trf.simulate(resps - pad)\n",
    "        trdict[story] = [trf]\n",
    "    return trdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f7c898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.DATA_TRAIN_DIR = \"/Users/gilad/Desktop/Projects/Semantic Decoding/semantic-decoding/data_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c36f4b",
   "metadata": {},
   "source": [
    "### Get the words embedding (stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d994e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_word_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rstim, tr_stats, word_stats \u001b[38;5;241m=\u001b[39m \u001b[43mget_stim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m, in \u001b[0;36mget_stim\u001b[0;34m(stories, features, tr_stats)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stim\u001b[39m(stories, features, tr_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"extract quantitative features of stimulus stories\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     word_seqs \u001b[38;5;241m=\u001b[39m \u001b[43mget_story_wordseqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     word_vecs \u001b[38;5;241m=\u001b[39m {story : features\u001b[38;5;241m.\u001b[39mmake_stim(word_seqs[story]\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;28;01mfor\u001b[39;00m story \u001b[38;5;129;01min\u001b[39;00m stories}\n\u001b[1;32m      6\u001b[0m     word_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([word_vecs[story] \u001b[38;5;28;01mfor\u001b[39;00m story \u001b[38;5;129;01min\u001b[39;00m stories])\n",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m, in \u001b[0;36mget_story_wordseqs\u001b[0;34m(stories)\u001b[0m\n\u001b[1;32m      6\u001b[0m     respdict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m trfiles \u001b[38;5;241m=\u001b[39m load_simulated_trfiles(respdict)\n\u001b[0;32m----> 8\u001b[0m wordseqs \u001b[38;5;241m=\u001b[39m \u001b[43mmake_word_ds\u001b[49m(grids, trfiles)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wordseqs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_word_ds' is not defined"
     ]
    }
   ],
   "source": [
    "rstim, tr_stats, word_stats = get_stim(stories, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13545fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rstim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e2d10",
   "metadata": {},
   "source": [
    "### Get the response (fMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rresp = get_resp(subject, stories, stack = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5577e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rresp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrresp\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rresp' is not defined"
     ]
    }
   ],
   "source": [
    "rresp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2aedf",
   "metadata": {},
   "source": [
    "### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "faa2563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nchunks = int(np.ceil(rresp.shape[0] / 5 / config.CHUNKLEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d336b0",
   "metadata": {},
   "source": [
    "### Estimate the ridge model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f46f7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, alphas, bscorrs = bootstrap_ridge(rstim, rresp, use_corr = False, alphas = config.ALPHAS,\n",
    "    nboots = config.NBOOTS, chunklen = config.CHUNKLEN, nchunks = nchunks)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f1b8ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 81126)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0edd91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 81126, 50)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bscorrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "246eba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bscorrs = bscorrs.mean(2).max(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8bb86c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81126,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bscorrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d27eb",
   "metadata": {},
   "source": [
    "### find the best correlated voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "faadd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = np.sort(np.argsort(bscorrs)[-config.VOXELS:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3624cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rstim, rresp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2684788",
   "metadata": {},
   "source": [
    "### Estimate noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9118529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_dict = {story : get_stim([story], features, tr_stats = tr_stats) for story in stories}\n",
    "resp_dict = get_resp(subject, stories, stack = False, vox = vox)\n",
    "noise_model = np.zeros([len(vox), len(vox)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "765febe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hstory in stories:\n",
    "    tstim, hstim = np.vstack([stim_dict[tstory] for tstory in stories if tstory != hstory]), stim_dict[hstory]\n",
    "    tresp, hresp = np.vstack([resp_dict[tstory] for tstory in stories if tstory != hstory]), resp_dict[hstory]\n",
    "    # use the previously calculated alphas for each voxel, now to estimate the correlation between stimuli and response\n",
    "    bs_weights = ridge(tstim, tresp, alphas[vox])\n",
    "    # find the residuals (the parts that are not explained by the model)\n",
    "    resids = hresp - hstim.dot(bs_weights)\n",
    "    \n",
    "    # the noise model which is the amount of noise per story (normalized)\n",
    "    bs_noise_model = resids.T.dot(resids)\n",
    "    noise_model += bs_noise_model / np.diag(bs_noise_model).mean() / len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "16418627",
   "metadata": {},
   "outputs": [],
   "source": [
    "del stim_dict, resp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6064b370",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "103b261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GPT.GPT at 0x7fac00171ac0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52896f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = os.path.join(config.MODEL_DIR, subject)\n",
    "os.makedirs(save_location, exist_ok = True)\n",
    "np.savez(os.path.join(save_location, \"encoding_model_%s\" % \"percieved\"),\n",
    "weights = weights, noise_model = noise_model, alphas = alphas, voxels = vox, stories = stories,\n",
    "tr_stats = np.array(tr_stats), word_stats = np.array(word_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8eee5f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gilad/Desktop/Projects/Semantic Decoding/semantic-decoding/decoding/models/UTS01'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "231104c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilad/Desktop/Projects/Semantic Decoding/semantic-decoding/decoding/models/UTS01\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/gilad/Desktop/Projects/Semantic Decoding/semantic-decoding/decoding/models/UTS01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8215a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding_model_<GPT.GPT object at 0x7fac00171ac0>.npz\r\n",
      "encoding_model_percieved.npz\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2198055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 10939184\r\n",
      "-rw-r--r--  1 gilad  staff  2794502468 Sep 21 17:56 encoding_model_<GPT.GPT object at 0x7fac00171ac0>.npz\r\n",
      "-rw-r--r--  1 gilad  staff  2794502468 Sep 21 18:00 encoding_model_percieved.npz\r\n"
     ]
    }
   ],
   "source": [
    "%ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362536a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
